{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|██████████| 21336/21336 [18:26<00:00, 19.29it/s]\n",
      "Copying files: 100%|██████████| 5335/5335 [04:50<00:00, 18.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 훈련, 검증 세트 분할\n",
    "def split_data(src_dir, train_dst_dir, val_dst_dir, train_ratio):\n",
    "    # 지정된 디렉토리에서 이미지 파일과 JSON 파일 목록을 가져옵니다.\n",
    "    img_files = glob.glob(src_dir + '/*.jpg')\n",
    "    json_files = glob.glob(src_dir + '/*.json')\n",
    "\n",
    "    # 파일 목록을 무작위로 섞습니다.\n",
    "    random.shuffle(img_files)\n",
    "\n",
    "    # 훈련 데이터의 개수를 계산합니다.\n",
    "    num_train = int(len(img_files) * train_ratio)\n",
    "\n",
    "    # 파일 목록을 훈련용과 검증용으로 분할합니다.\n",
    "    train_files = img_files[:num_train]\n",
    "    val_files = img_files[num_train:]\n",
    "\n",
    "    # 훈련용 데이터를 복사합니다.\n",
    "    for filepath in tqdm(train_files, desc='Copying files'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        shutil.copy2(filepath, os.path.join(train_dst_dir, filename))  # 이미지 파일 복사\n",
    "        shutil.copy2(filepath.replace('.jpg', '.json'), os.path.join(train_dst_dir, filename.replace('.jpg', '.json')))  # JSON 파일 복사\n",
    "\n",
    "    # 검증용 데이터를 복사합니다.\n",
    "    for filepath in tqdm(val_files, desc='Copying files'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        shutil.copy2(filepath, os.path.join(val_dst_dir, filename))  # 이미지 파일 복사\n",
    "        shutil.copy2(filepath.replace('.jpg', '.json'), os.path.join(val_dst_dir, filename.replace('.jpg', '.json')))  # JSON 파일 복사\n",
    "\n",
    "# 실행 예시\n",
    "src_dir = 'D:/Study/TeamProject_2/dataset_filtered'  # 원본 데이터셋 경로\n",
    "train_dst_dir = 'D:/Study/TeamProject_2/dataset_filtered/train'  # 훈련 데이터셋 경로\n",
    "val_dst_dir = 'D:/Study/TeamProject_2/dataset_filtered/val'  # 검증 데이터셋 경로\n",
    "train_ratio = 0.8  # 훈련 데이터의 비율\n",
    "\n",
    "# 훈련용 및 검증용 폴더가 없을 경우 생성합니다.\n",
    "os.makedirs(train_dst_dir, exist_ok=True)\n",
    "os.makedirs(val_dst_dir, exist_ok=True)\n",
    "\n",
    "split_data(src_dir, train_dst_dir, val_dst_dir, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "def create_tf_example(json_path, img_path):\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    width = data['description']['imageWidth']\n",
    "    height = data['description']['imageHeight']\n",
    "\n",
    "    filename = data['info']['video_id'].encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "\n",
    "    xmins = [] \n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    # environment annotations\n",
    "    for annotation in data['annotations']['environment']:\n",
    "        points = annotation['points']\n",
    "        x_values = [point[0] for point in points]\n",
    "        y_values = [point[1] for point in points]\n",
    "        xmins.append(min(x_values) / width)\n",
    "        xmaxs.append(max(x_values) / width)\n",
    "        ymins.append(min(y_values) / height)\n",
    "        ymaxs.append(max(y_values) / height)\n",
    "        classes_text.append((\"environment_\" + annotation['area_code']).encode('utf8'))\n",
    "        # TODO: Add class ID conversion here\n",
    "        # classes.append(class_to_id_dict[annotation['class']])\n",
    "\n",
    "    # PM annotations\n",
    "    for annotation in data['annotations']['PM']:\n",
    "        points = annotation['points']\n",
    "        xmins.append(points[0] / width)\n",
    "        xmaxs.append((points[0] + points[2]) / width)\n",
    "        ymins.append(points[1] / height)\n",
    "        ymaxs.append((points[1] + points[3]) / height)\n",
    "        classes_text.append((\"PM_\" + annotation['PM_code']).encode('utf8'))\n",
    "        # TODO: Add class ID conversion here\n",
    "        # classes.append(class_to_id_dict[annotation['class']])\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_jpg])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 21336/21336 [17:36<00:00, 20.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# 훈련 데이터 TFRecord 파일 생성\n",
    "# 이미지와 JSON 파일이 위치한 디렉토리\n",
    "dir_path = 'D:/Study/TeamProject_2/dataset_filtered/train'\n",
    "\n",
    "# JSON 파일 경로들을 가져옵니다\n",
    "json_paths = glob(os.path.join(dir_path, '*.json'))\n",
    "\n",
    "# TFRecord를 저장할 writer를 생성합니다\n",
    "writer = tf.io.TFRecordWriter('train.tfrecord')\n",
    "\n",
    "for json_path in tqdm(json_paths, desc=\"Processing data\"):\n",
    "    # JSON 파일과 같은 이름의 이미지 파일 경로를 가져옵니다\n",
    "    img_path = os.path.splitext(json_path)[0] + '.jpg'\n",
    "    \n",
    "    # JSON과 이미지 파일을 이용하여 TFRecord를 생성하고, 이를 파일에 씁니다\n",
    "    tf_example = create_tf_example(json_path, img_path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 5335/5335 [03:37<00:00, 24.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 TFRecord 파일 생성\n",
    "# 이미지와 JSON 파일이 위치한 디렉토리\n",
    "dir_path = 'D:/Study/TeamProject_2/dataset_filtered/val'\n",
    "\n",
    "# JSON 파일 경로들을 가져옵니다\n",
    "json_paths = glob(os.path.join(dir_path, '*.json'))\n",
    "\n",
    "# TFRecord를 저장할 writer를 생성합니다\n",
    "writer = tf.io.TFRecordWriter('val.tfrecord')\n",
    "\n",
    "for json_path in tqdm(json_paths, desc=\"Processing data\"):\n",
    "    # JSON 파일과 같은 이름의 이미지 파일 경로를 가져옵니다\n",
    "    img_path = os.path.splitext(json_path)[0] + '.jpg'\n",
    "    \n",
    "    # JSON과 이미지 파일을 이용하여 TFRecord를 생성하고, 이를 파일에 씁니다\n",
    "    tf_example = create_tf_example(json_path, img_path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
