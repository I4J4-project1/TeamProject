네, 맞습니다. 웹페이지의 HTML을 스크래핑하는 것과 API를 통해 데이터를 수집하는 것은 다른 접근 방식입니다.

1. 웹 스크래핑(Web Scraping): 이 방법은 웹페이지의 HTML 코드를 분석하여 필요한 데이터를 추출하는 과정을 말합니다.
파이썬에서는 BeautifulSoup, Scrapy와 같은 라이브러리를 사용하여 웹 스크래핑을 수행할 수 있습니다.
웹 스크래핑은 웹사이트의 구조가 변경되었을 때 코드를 업데이트해야 하는 등의 문제점이 있습니다.
또한, 웹사이트의 서비스 이용약관에서 스크래핑을 금지하고 있을 수도 있으니 주의해야 합니다.

2. API 사용: API(Application Programming Interface)는 서버와 클라이언트 간에 데이터를 교환하는 방법입니다.
서버는 클라이언트의 요청에 따라 데이터를 반환하며, 이 데이터는 보통 JSON이나 XML 형식으로 제공됩니다.
API를 사용하면 웹 스크래핑보다 효율적이고 안정적인 방법으로 데이터를 수집할 수 있습니다.
단, API를 제공하는 서비스에서 요구하는 규격에 맞추어 요청을 보내야 하며, 대부분의 경우 특정한 인증(예: API Key)이 필요합니다.

따라서, 데이터를 수집하는 방법은 웹페이지의 구조, 제공되는 API, 개인의 필요에 따라 결정됩니다.
어떤 방식을 사용할지는 사용자가 결정하면 됩니다.

echo 'export PATH=$PATH:/d/Study/ffmpeg/bin' >> ~/.bashrc

왜 git bash로는 ffmpeg실행이 안되는지?(cmd는 됨)
환경설정 경로는 다음과 같이 제대로 되어있음(경로를 직접 입력하면 실행도 됨)
export PATH=$PATH:/d/Study/ffmpeg/bin

echo 'export PATH="/d/Study/ffmpeg/bin:$PATH"' >> ~/.bashrc 로 해도 왜 터미널을 실행할 때 초기화가 되는지?

export PATH="/d/Study/ffmpeg/bin:$PATH" 를 실행할 때 마다 해줘야함...

자바스크립트로 동적으로 생성된 정보를 가져오려면 Selenium을 사용해야 한다.
따라서 도시교통정보센터에서 제공한 API를 활용하기 위해 Selenium가 필요하다.