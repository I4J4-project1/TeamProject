{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_images_in_folder(folder_path, target_size=(640,640)):\n",
    "    # 폴더 내 모든 파일을 순회한다.\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # 이미지 파일 경로를 생성한다.\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # 이미지를 읽는다.\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"Image not found at {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # OpenCV로 이미지를 BGR에서 RGB로 변환한다. (OpenCV는 기본적으로 BGR로 이미지를 읽기때문에 다른 도구와 호환되도록 RGB로 변환해야 한다.)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 이미지 크기를 재조정한다.\n",
    "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "        # 이미지를 정규화하거나 추가 전처리를 수행한다.\n",
    "        img = preprocess_input(img)\n",
    "\n",
    "        # 네트워크 입력에 맞게 차원을 추가한다.\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # 전처리가 완료된 이미지를 반환한다.\n",
    "        yield img, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"E:\\\\Study\\\\TeamProject_2\\\\Dataset_CCTV\\\\Image_Data\\\\야간\\\\우천\\\\연출\"\n",
    "\n",
    "data = [img for img, _ in preprocess_images_in_folder(folder_path)]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 이미지 데이터 형태: (12, 1, 640, 640, 3)\n",
      "리사이징된 이미지 데이터 형태: (12, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 모든 이미지를 저장할 빈 리스트를 생성합니다.\n",
    "resized_images = []\n",
    "\n",
    "# 원본 이미지 데이터셋을 반복하여 각 이미지를 리사이징합니다.\n",
    "for img in data:\n",
    "    img = img[0]  # 이미지를 추출합니다. 데이터셋이 5차원이므로 4차원으로 줄입니다.\n",
    "    resized_img = cv2.resize(img, (640, 640))  # 이미지를 640x640 크기로 리사이징합니다.\n",
    "    resized_images.append(resized_img)  # 리사이징된 이미지를 리스트에 추가합니다.\n",
    "\n",
    "# 리스트를 넘파이 배열로 변환합니다.\n",
    "resized_images = np.array(resized_images)\n",
    "\n",
    "# 결과를 확인합니다.\n",
    "print(\"원본 이미지 데이터 형태:\", data.shape)\n",
    "print(\"리사이징된 이미지 데이터 형태:\", resized_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_annotations_from_folder(folder_path):\n",
    "    annotations = []\n",
    "    for json_file in os.listdir(folder_path):\n",
    "        if json_file.endswith(\".json\"):\n",
    "            with open(os.path.join(folder_path, json_file)) as file:\n",
    "                annotation = json.load(file)\n",
    "                for pm_annotation in annotation[\"annotations\"][\"PM\"]:\n",
    "                    bbox = pm_annotation[\"points\"]\n",
    "                    class_label = int(pm_annotation[\"PM_code\"])  # Assuming class labels are integers\n",
    "                    annotations.append((bbox, class_label))\n",
    "    return annotations\n",
    "\n",
    "folder_path = \"E:\\Study\\TeamProject_2\\Dataset_CCTV\\Labeling_Data\\CCTV\\야간\\우천\\연출\"\n",
    "annotations_list = load_annotations_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_array = []\n",
    "\n",
    "for annotation in annotations_list:\n",
    "    # 'points' list and 'class' into a single list\n",
    "    combined = annotation[0] + [annotation[1]]\n",
    "    annotations_array.append(combined)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "annotations_array = np.array(annotations_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, labels):\n",
    "    # 이미지 전처리\n",
    "    image = tf.image.resize(image, (640, 640))\n",
    "    image = image / 255.0  # 이미지 정규화\n",
    "\n",
    "    # 라벨을 네트워크 출력 형태에 맞게 변환\n",
    "    # 바운딩 박스 좌표\n",
    "    bbox = labels[0]\n",
    "    # 클래스 ID를 one-hot 벡터로 변환\n",
    "    class_id = tf.one_hot(labels[1], depth=21)\n",
    "\n",
    "    return image, tf.concat([bbox, class_id], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def preprocess_data(image, labels):\n",
    "    # 이미지 전처리 (이미지 크기 조정, 정규화 등)\n",
    "    image = tf.image.resize(image, (640, 640))\n",
    "    image = image / 255.0  # 이미지 정규화\n",
    "\n",
    "    # 라벨을 네트워크 출력 형태에 맞게 변환\n",
    "    # 예: 그리드 셀로 이미지를 분할하고, 각 셀의 클래스와 바운딩 박스를 계산\n",
    "    # 이 부분은 네트워크 구조와 문제에 따라 다르게 구현해야 합니다.\n",
    "    # TODO: labels를 적절한 형태로 변환하는 코드를 작성해야 합니다.\n",
    "\n",
    "    return image, labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\k10dh\\AppData\\Local\\Temp\\ipykernel_40832\\205698403.py\", line 10, in preprocess_data  *\n        class_id = tf.one_hot(labels[1], depth=21)\n\n    TypeError: Value passed to parameter 'indices' has DataType float64 not in list of allowed values: uint8, int8, int32, int64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m labels \u001b[39m=\u001b[39m load_annotations_from_folder(folder_path_label)\n\u001b[0;32m      8\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((images, annotations_array))\n\u001b[1;32m----> 9\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(preprocess_data)\n\u001b[0;32m     11\u001b[0m \u001b[39m# 데이터셋 셔플, 배치 사이즈 설정, 프리페치(성능 최적화)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mbatch(\u001b[39m512\u001b[39m)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[0;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2242\u001b[0m     map_func,\n\u001b[0;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[0;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m    108\u001b[0m     map_func,\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    170\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filepii4covq.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_data\u001b[1;34m(image, labels)\u001b[0m\n\u001b[0;32m     11\u001b[0m image \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(image) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m     12\u001b[0m bbox \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(labels)[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m class_id \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mone_hot, (ag__\u001b[39m.\u001b[39;49mld(labels)[\u001b[39m1\u001b[39;49m],), \u001b[39mdict\u001b[39;49m(depth\u001b[39m=\u001b[39;49m\u001b[39m21\u001b[39;49m), fscope)\n\u001b[0;32m     14\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:56\u001b[0m, in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     54\u001b[0m allowed_values \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(dtypes\u001b[39m.\u001b[39mas_dtype(x)\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m allowed_list)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_list:\n\u001b[1;32m---> 56\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     57\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValue passed to parameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has DataType \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m not in list of allowed values: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mallowed_values\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\k10dh\\AppData\\Local\\Temp\\ipykernel_40832\\205698403.py\", line 10, in preprocess_data  *\n        class_id = tf.one_hot(labels[1], depth=21)\n\n    TypeError: Value passed to parameter 'indices' has DataType float64 not in list of allowed values: uint8, int8, int32, int64\n"
     ]
    }
   ],
   "source": [
    "# tf.data.Dataset을 생성\n",
    "folder_path_images = \"E:\\\\Study\\\\TeamProject_2\\\\Dataset_CCTV\\\\Image_Data\\\\야간\\\\우천\\\\연출\"\n",
    "images = [img for img, _ in preprocess_images_in_folder(folder_path_images)]\n",
    "\n",
    "folder_path_label = \"E:\\Study\\TeamProject_2\\Dataset_CCTV\\Labeling_Data\\CCTV\\야간\\우천\\연출\"\n",
    "labels = load_annotations_from_folder(folder_path_label)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, annotations_array))\n",
    "dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# 데이터셋 셔플, 배치 사이즈 설정, 프리페치(성능 최적화)\n",
    "dataset = dataset.shuffle(1024).batch(512).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, Input, TimeDistributed, Dense, Flatten, Dropout\n",
    "\n",
    "def create_model(num_classes): # 감지하려는 클래스의 종류\n",
    "    input_tensor = Input(shape=(640, 640, 3))\n",
    "\n",
    "    # Backbone Network\n",
    "    base_model = ResNet50(include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "    # RPN Layer\n",
    "    rpn_layer = Conv2D(512, (3, 3), padding='same', activation='relu', \n",
    "                       kernel_initializer='normal', name='rpn_conv1')(base_model.output)\n",
    "    \n",
    "    # Classifier Layer\n",
    "    classification_layer = TimeDistributed(Dense(num_classes, activation='softmax'), name='classification_layer')(rpn_layer)\n",
    "    bbox_regression_layer = TimeDistributed(Dense(num_classes * 4, activation='linear'), name='bbox_regression_layer')(rpn_layer)\n",
    "    \n",
    "    return Model(inputs=input_tensor, outputs=[classification_layer, bbox_regression_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(21)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'classification_layer': 'categorical_crossentropy', \n",
    "                    'bbox_regression_layer': 'mean_squared_error'}, \n",
    "              metrics={'classification_layer': 'accuracy',\n",
    "                       'bbox_regression_layer': 'mse'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 20, 20, 21) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(resized_images, annotations_array, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filempa4dl_g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\k10dh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 20, 20, 21) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(resized_images, annotations_array, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
